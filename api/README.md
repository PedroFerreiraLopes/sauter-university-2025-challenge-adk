# ReservatÃ³rios API

Uma API FastAPI completa para gerenciar pipelines de dados de reservatÃ³rios da ONS (Operador Nacional do Sistema ElÃ©trico) e consultar dados armazenados no Google BigQuery.

## ğŸ“‹ VisÃ£o Geral

Esta API oferece trÃªs funcionalidades principais:

1. **Health Check**: VerificaÃ§Ã£o do status da aplicaÃ§Ã£o
2. **Pipeline Management**: Disparo e execuÃ§Ã£o da pipeline ETL (Extract, Transform, Load)
3. **Data Querying**: Consulta de dados processados no BigQuery

A aplicaÃ§Ã£o estÃ¡ estruturada seguindo as melhores prÃ¡ticas de desenvolvimento, com separaÃ§Ã£o clara de responsabilidades entre routers, services, utils e pipeline.

## ğŸ—ï¸ Arquitetura

```
api/
â”œâ”€â”€ src/app/                    # CÃ³digo principal da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ main.py                # Ponto de entrada da FastAPI
â”‚   â”œâ”€â”€ pipeline_client.py     # Cliente para execuÃ§Ã£o da pipeline
â”‚   â”œâ”€â”€ routers/               # Endpoints da API
â”‚   â”‚   â”œâ”€â”€ health.py         # Health check
â”‚   â”‚   â”œâ”€â”€ pipeline.py       # Gerenciamento da pipeline
â”‚   â”‚   â””â”€â”€ data.py           # Consulta de dados
â”‚   â”œâ”€â”€ services/             # ServiÃ§os de negÃ³cio
â”‚   â”‚   â””â”€â”€ bigquery_service.py # IntegraÃ§Ã£o com BigQuery
â”‚   â””â”€â”€ utils/                # UtilitÃ¡rios
â”‚       â””â”€â”€ logger.py         # ConfiguraÃ§Ã£o de logging
â”œâ”€â”€ pipeline/                 # MÃ³dulos ETL
â”‚   â”œâ”€â”€ extract.py           # ExtraÃ§Ã£o de dados da API ONS
â”‚   â”œâ”€â”€ transform.py         # TransformaÃ§Ã£o e limpeza dos dados
â”‚   â””â”€â”€ load.py              # Carregamento no BigQuery/GCS
â””â”€â”€ Dockerfile               # Container Docker
```

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Python 3.11+
- Google Cloud SDK configurado
- Credenciais do Google Cloud com acesso ao BigQuery
- UV (recomendado) ou pip para gerenciamento de dependÃªncias

### 1. ConfiguraÃ§Ã£o do Ambiente

```bash
# Clone o repositÃ³rio (se necessÃ¡rio)
cd api

# Crie e ative um ambiente virtual (opcional com UV)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Instale as dependÃªncias
uv pip install -r src/app/requirements.txt
# ou
pip install -r src/app/requirements.txt
```

### 2. ConfiguraÃ§Ã£o das VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto api com:

```env
# Google Cloud
GOOGLE_CLOUD_PROJECT=seu-projeto-gcp
GOOGLE_CLOUD_LOCATION=us-central1
GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account.json

# BigQuery
TABLE_ID=seu-projeto.dataset.tabela

# Storage (se usar GCS)
BUCKET_NAME=seu-bucket-gcs
```

### 3. Executar a AplicaÃ§Ã£o

#### Desenvolvimento Local

```bash
cd src/app
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

#### ProduÃ§Ã£o

```bash
cd src/app
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

### 4. Executar com Docker

```bash
# Build da imagem
docker build -t reservatorios-api .

# Executar o container
docker run -p 8000:8000 \
  -e GOOGLE_CLOUD_PROJECT=seu-projeto \
  -v /path/to/credentials.json:/app/credentials.json \
  -e GOOGLE_APPLICATION_CREDENTIALS=/app/credentials.json \
  reservatorios-api
```

## ğŸ“š Endpoints da API

### Health Check
- **GET** `/api/v1/health/health`
- Verifica se a aplicaÃ§Ã£o estÃ¡ funcionando

### Pipeline
- **POST** `/api/v1/pipeline/pipeline`
- Dispara a execuÃ§Ã£o da pipeline ETL em background

### Dados
- **GET** `/api/v1/data/data`
- Consulta dados no BigQuery
- ParÃ¢metros:
  - `limit`: NÃºmero mÃ¡ximo de registros (1-1000, padrÃ£o: 100)
  - `offset`: NÃºmero de registros a pular (padrÃ£o: 0)
  - `date`: Filtrar por data (formato: YYYY-MM-DD)

## ğŸ”„ Pipeline ETL

A pipeline Ã© composta por trÃªs etapas:

### 1. Extract (`pipeline/extract.py`)
- Conecta Ã  API da ONS
- Baixa arquivos Parquet mais recentes por ano
- Salva localmente na pasta `downloads/`

### 2. Transform (`pipeline/transform.py`)
- Carrega arquivos Parquet
- Combina dados de diferentes anos
- Remove colunas desnecessÃ¡rias
- Normaliza tipos de dados

### 3. Load (`pipeline/load.py`)
- Carrega dados transformados no BigQuery
- Opcional: backup no Google Cloud Storage

## ğŸ“– DocumentaÃ§Ã£o da API

ApÃ³s iniciar a aplicaÃ§Ã£o, acesse:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ³ Deploy com Google Cloud Build

O projeto inclui configuraÃ§Ã£o para deploy automÃ¡tico:

```bash
# Submit build para Google Cloud
gcloud builds submit --config cloudbuild.yaml .
```

## ğŸ§ª Testes

```bash
# Instalar dependÃªncias de desenvolvimento
pip install -e ".[dev]"

# Executar testes
pytest

# Executar com coverage
pytest --cov=src
```

## ğŸ“ Logs

Os logs sÃ£o configurados automaticamente e incluem:
- InformaÃ§Ãµes de requisiÃ§Ãµes HTTP
- Status da pipeline ETL
- Erros e exceÃ§Ãµes
- Consultas ao BigQuery

## âš ï¸ Troubleshooting

### Problemas Comuns

1. **Erro de autenticaÃ§Ã£o Google Cloud**
   - Verifique se `GOOGLE_APPLICATION_CREDENTIALS` aponta para arquivo vÃ¡lido
   - Confirme que a service account tem permissÃµes necessÃ¡rias

2. **Pipeline nÃ£o executa**
   - Verifique logs em `/pipeline/logs/`
   - Confirme conectividade com API da ONS
   - Verifique espaÃ§o em disco para downloads

3. **Consultas BigQuery falham**
   - Confirme que a tabela existe no BigQuery
   - Verifique permissÃµes da service account
   - Valide formato do `TABLE_ID`

### Comandos Ãšteis

```bash
# Verificar logs da aplicaÃ§Ã£o
tail -f pipeline/logs/app.log

# Testar conectividade com BigQuery
python -c "from google.cloud import bigquery; print(bigquery.Client().list_datasets())"

# Verificar arquivos baixados
ls -la downloads/
```

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### CustomizaÃ§Ã£o da Pipeline

Para modificar a pipeline, edite os arquivos em `pipeline/`:
- `extract.py`: Alterar fonte de dados ou filtros
- `transform.py`: Modificar transformaÃ§Ãµes e limpeza
- `load.py`: Alterar destino ou formato de saÃ­da

### ConfiguraÃ§Ã£o do BigQuery

Certifique-se de que sua tabela BigQuery tenha o schema compatÃ­vel com os dados da ONS:
```sql
CREATE TABLE `projeto.dataset.tabela` (
  nom_reservatorio STRING,
  tip_reservatorio STRING,
  nom_bacia STRING,
  nom_ree STRING,
  id_subsistema STRING,
  nom_subsistema STRING,
  ear_data DATE,
  -- outros campos numÃ©ricos como FLOAT64
);
```

## ğŸ“ Suporte

Para dÃºvidas ou problemas:
1. Verifique os logs da aplicaÃ§Ã£o
2. Consulte a documentaÃ§Ã£o do Google Cloud
3. Revisite este README para configuraÃ§Ãµes